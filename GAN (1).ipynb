{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UP7BddKYBKv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#!pip install torch_geometric\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='./data', name='Cora', transform=NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "\n",
        "print(data)\n",
        "print(\"Nodes:\", data.num_nodes)\n",
        "print(\"Edges:\", data.edge_index.shape[1])\n",
        "print(\"Features per node:\", dataset.num_features)\n",
        "print(\"Num classes:\", dataset.num_classes)\n",
        "print(data.x.shape)\n",
        "print(data.y.shape)\n",
        "print (\"Train/Val/Test sizes:\", int(data.train_mask.sum()), int(data.val_mask.sum()), int(data.test_mask.sum()))\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=8, dropout=0.6):\n",
        "      super(GAT, self).__init__()\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "      self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "      self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "      x = self.dropout(x)\n",
        "      x = self.conv1(x, edge_index)\n",
        "      x = F.elu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.conv2(x, edge_index)\n",
        "      return x\n",
        "\n",
        "# Test to make sure out.shape matches data.num_nodes, and dataset.num_classes\n",
        "#model = GAT(in_channels=dataset.num_features,\n",
        "#            hidden_channels=8,\n",
        "#            out_channels=dataset.num_classes,\n",
        "#            heads=8,\n",
        "#            dropout=0.6)\n",
        "#out = model(data.x, data.edge_index)\n",
        "#print(\"Expected Shape:\", out.shape)  # should be [data.num_nodes, dataset.num_classes]\n",
        "\n",
        "def main():\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  graph = data.to(device)\n",
        "  model = GAT(in_channels=dataset.num_features,\n",
        "              hidden_channels=8,\n",
        "              out_channels=dataset.num_classes,\n",
        "              heads=8,\n",
        "              dropout=0.6).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def train_epoch():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(graph.x, graph.edge_index)\n",
        "    loss = criterion(logits[graph.train_mask], graph.y[graph.train_mask])\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "  def accuracy(mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      logits = model(graph.x, graph.edge_index)\n",
        "      pred = logits.argmax(dim=1)\n",
        "      acc = (pred[mask] == graph.y[mask]).float().mean().item()\n",
        "      return acc\n",
        "\n",
        "  best_val = 0.0\n",
        "  best_state = None\n",
        "  test_at_best = None\n",
        "\n",
        "  for epoch in range(1, 201):\n",
        "    loss = train_epoch()\n",
        "    train_acc = accuracy(graph.train_mask)\n",
        "    val_acc = accuracy(graph.val_mask)\n",
        "    test_acc = accuracy(graph.test_mask)\n",
        "\n",
        "    if val_acc > best_val:\n",
        "      best_val = val_acc\n",
        "      best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "      test_at_best = accuracy(data.test_mask)\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
        "    else:\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
        "\n",
        "  if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "  final_test= accuracy(graph.test_mask)\n",
        "  print(f\"Best Val {best_val:.3f} | Final Test {test_acc:.3f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test to make sure out.shape matches data.num_nodes, and dataset.num_classes\n",
        "#model = GAT(in_channels=dataset.num_features,\n",
        "#            hidden_channels=8,\n",
        "#            out_channels=dataset.num_classes,\n",
        "#            heads=8,\n",
        "#            dropout=0.6)\n",
        "#out = model(data.x, data.edge_index)\n",
        "#print(\"Expected Shape:\", out.shape)  # should be [data.num_nodes, dataset.num_classes]"
      ],
      "metadata": {
        "id": "FBkRHw4YH4X1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}